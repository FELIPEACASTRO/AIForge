# Tree-of-Thoughts (ToT)

## Description
O **Tree-of-Thoughts (ToT)** é uma estrutura que generaliza a técnica de prompt **Chain-of-Thought (CoT)**. Em vez de uma sequência linear de etapas de raciocínio, o ToT estrutura o processo de resolução de problemas como uma **árvore**, onde 'pensamentos' são unidades de texto coerentes e intermediárias. Isso permite que o Grande Modelo de Linguagem (LLM) explore múltiplos caminhos de raciocínio simultaneamente, realize autoavaliação das escolhas, antecipe e retroceda quando um caminho se mostrar improdutivo. Essa abordagem possibilita um raciocínio mais deliberado, do tipo 'Sistema 2', melhorando significativamente a capacidade do LLM de lidar com tarefas complexas que exigem planejamento não trivial, busca ou tomada de decisão estratégica.

## Examples
```
**Exemplo 1: Jogo do 24 (Lógica)**\n**Objetivo:** Usar os números 4, 6, 7, 8 exatamente uma vez com operações aritméticas padrão (+, -, *, /) para chegar a 24.\n**Prompt:**\n1. **Gerar Pensamentos:** Proponha 3 combinações iniciais distintas (por exemplo, dois números combinados) e os números restantes para cada caminho.\n2. **Avaliar Pensamentos:** Pontue cada caminho (1-5) com base em quão próximo o resultado está de um fator de 24 (por exemplo, 2, 3, 4, 6, 8, 12) ou do próprio 24.\n3. **Selecionar e Continuar:** Escolha o caminho com a pontuação mais alta e repita o processo (Gerar, Avaliar, Selecionar) até que 24 seja alcançado ou todos os caminhos se esgotem.\n4. **Resposta Final:** Declare a expressão final.\n\n**Exemplo 2: Escrita Criativa (Planejamento de Enredo)**\n**Objetivo:** Desenvolver o próximo ponto principal do enredo para um romance de fantasia onde o protagonista, um jovem mago, acaba de descobrir um artefato poderoso e oculto.\n**Prompt:**\n1. **Gerar Pensamentos:** Crie 3 opções de enredo distintas e de alto risco para o efeito imediato do artefato no mundo (por exemplo, 'Ele desencadeia uma tempestade mágica', 'Ele desperta um guardião ancestral', 'Ele é imediatamente roubado pelo antagonista').\n2. **Avaliar Pensamentos:** Avalie cada opção com base em (a) tensão dramática, (b) alinhamento com o arco do personagem e (c) originalidade (1-5).\n3. **Selecionar e Continuar:** Selecione a opção com a maior pontuação combinada. Em seguida, gere 3 sub-pensamentos (próximas etapas) para o ponto de enredo escolhido.\n4. **Resposta Final:** Descreva o ponto de enredo escolhido e as consequências imediatas em detalhes.\n\n**Exemplo 3: Planejamento Estratégico (Decisão de Negócios)**\n**Objetivo:** Determinar a melhor estratégia de entrada no mercado para uma nova marca de café sustentável em um mercado saturado.\n**Prompt:**\n1. **Gerar Pensamentos:** Proponha 3 estratégias iniciais de entrada no mercado (por exemplo, 'Focar em e-commerce e marketing de mídia social', 'Fazer parceria com uma grande rede de supermercados', 'Abrir uma loja principal em uma área de alto tráfego').\n2. **Avaliar Pensamentos:** Para cada estratégia, avalie o (a) custo inicial, (b) alcance potencial e (c) nível de risco (Baixo, Médio, Alto).\n3. **Selecionar e Continuar:** Escolha a estratégia com o melhor equilíbrio entre alcance e risco. Em seguida, gere 3 sub-pensamentos de implementação (por exemplo, 'Definir as 3 primeiras ações de marketing', 'Identificar 3 parceiros potenciais', 'Selecionar 3 locais-alvo').\n4. **Resposta Final:** Apresente a estratégia escolhida, sua justificativa e as três primeiras etapas do plano de implementação.\n\n**Exemplo 4: Depuração de Código (Análise da Causa Raiz)**\n**Objetivo:** Uma função Python que processa dados do usuário está falhando intermitentemente com um 'KeyError'. Analise as potenciais causas raiz.\n**Prompt:**\n1. **Gerar Pensamentos:** Proponha 3 categorias distintas de potenciais causas raiz (por exemplo, 'Falha na Validação de Dados de Entrada', 'Condição de Corrida Assíncrona', 'Mudança na API Externa').\n2. **Avaliar Pensamentos:** Para cada categoria, proponha um teste ou log específico para confirmar a hipótese. Pontue a probabilidade de cada causa (1-5).\n3. **Selecionar e Continuar:** Selecione a causa mais provável. Gere 3 sub-pensamentos específicos (por exemplo, 'Verificar o código de validação do esquema de dados', 'Revisar a documentação da API para mudanças recentes', 'Adicionar um mecanismo de bloqueio').\n4. **Resposta Final:** Identifique a causa raiz mais provável e a correção recomendada.\n\n**Exemplo 5: Palavras Cruzadas (Busca Intensiva)**\n**Objetivo:** Resolver um quebra-cabeça de palavras cruzadas 3x3 com as seguintes pistas: Horizontal 1: 'Veículo rápido' (3 letras), Vertical 1: 'Pequeno inseto' (3 letras), Vertical 2: 'Um tipo de árvore' (3 letras).\n**Prompt:**\n1. **Gerar Pensamentos:** Para a primeira pista ('Veículo rápido'), gere 3 possíveis palavras de 3 letras (por exemplo, 'CAR', 'JATO', 'BUS').\n2. **Avaliar Pensamentos:** Para cada palavra, verifique se ela permite palavras válidas para as pistas verticais que se cruzam. Pontue com base no número de possibilidades de cruzamento válidas.\n3. **Selecionar e Continuar:** Escolha a palavra com a pontuação mais alta. Repita o processo para a próxima pista de cruzamento, gerando novos pensamentos e avaliando-os com base nas restrições restantes.\n4. **Resposta Final:** Forneça a grade 3x3 preenchida.
```

## Best Practices
**Definir a Estrutura do Pensamento:** Instrua claramente o modelo sobre como gerar os 'pensamentos' (por exemplo, 'Gere 3 abordagens distintas para resolver este problema.').\n**Implementar Autoavaliação:** Exija que o modelo avalie a qualidade ou o potencial de cada pensamento/caminho gerado (por exemplo, 'Pontue cada abordagem de 1 a 5 com base na viabilidade e probabilidade de sucesso.').\n**Usar uma Estratégia de Busca:** Especifique o mecanismo de busca (por exemplo, Busca em Largura (BFS) para explorar muitas opções, ou Busca em Profundidade (DFS) para uma exploração mais profunda de um único caminho).\n**Refinamento Iterativo:** Instrua o modelo a selecionar o melhor pensamento e continuar o processo, ou a retroceder se o caminho atual falhar.\n**Manter Pensamentos Concisos:** Os pensamentos devem ser coerentes, mas não excessivamente prolixos, para gerenciar o tamanho da janela de contexto.

## Use Cases
**Quebra-Cabeças Matemáticos e Lógicos Complexos** (por exemplo, Jogo do 24).\n**Escrita Criativa e Planejamento de Histórias** (gerar múltiplos pontos de enredo e selecionar o melhor).\n**Planejamento Estratégico e Suporte à Decisão** (avaliar diferentes estratégias de negócios ou militares).\n**Geração e Depuração de Código** (explorar múltiplas estratégias de implementação ou correção).\n**Palavras Cruzadas e Outras Tarefas Intensivas em Busca**.

## Pitfalls
**Custo Computacional Elevado:** O ToT requer significativamente mais tokens e tempo de processamento do que o CoT devido à exploração de múltiplos ramos.\n**Estouro da Janela de Contexto:** Gerar muitos pensamentos ou pensamentos muito longos pode rapidamente exceder a janela de contexto do LLM, especialmente para buscas profundas.\n**Avaliação Subótima:** O mecanismo de autoavaliação do modelo pode ser falho, levando-o a podar um caminho promissor ou a seguir um beco sem saída.\n**Especificação Excessiva:** Instruções excessivamente rígidas sobre a estrutura da árvore podem limitar a flexibilidade de raciocínio natural do modelo.\n**Complexidade de Implementação:** Requer prompting mais complexo ou código externo (por exemplo, Python) para gerenciar a estrutura da árvore e o processo de busca.

## URL
[https://arxiv.org/abs/2305.10601](https://arxiv.org/abs/2305.10601)
