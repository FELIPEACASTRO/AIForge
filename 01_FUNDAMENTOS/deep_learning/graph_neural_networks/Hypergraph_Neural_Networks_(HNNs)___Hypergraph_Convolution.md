# Hypergraph Neural Networks (HNNs) / Hypergraph Convolution

## Description

**Redes Neurais de Hipergrafos (Hypergraph Neural Networks - HNNs)** são uma estrutura de aprendizado de representação de dados projetada para modelar e codificar **correlações de dados de ordem superior** que não podem ser capturadas por grafos tradicionais. Enquanto um grafo conecta pares de nós (relações de segunda ordem), um hipergrafo utiliza **hiperarestas** para conectar um número arbitrário de nós, permitindo a modelagem explícita de interações complexas e multimodais. O valor único das HNNs reside em sua capacidade de generalizar a convolução de grafos para hipergrafos através da **operação de convolução de hiperaresta**, permitindo a propagação eficiente de informações e o aprendizado de representações de camada oculta que consideram a estrutura de dados de ordem superior. Isso as torna superiores ao lidar com dados complexos e multimodais em comparação com as Redes Convolucionais de Grafos (GCNs) tradicionais. (EN: **Hypergraph Neural Networks (HNNs)** are a data representation learning framework designed to model and encode **higher-order data correlations** that cannot be captured by traditional graphs. While a graph connects pairs of nodes (second-order relations), a hypergraph uses **hyperedges** to connect an arbitrary number of nodes, allowing for the explicit modeling of complex and multimodal interactions. The unique value of HNNs lies in their ability to generalize graph convolution to hypergraphs through the **hyperedge convolution operation**, enabling efficient information propagation and the learning of hidden layer representations that consider the higher-order data structure. This makes them superior when dealing with complex and multimodal data compared to traditional Graph Convolutional Networks (GCNs).)\n\n**Convolução de Hipergrafo de Ordem Superior:** O termo refere-se à capacidade inerente das HNNs de capturar interações complexas que envolvem múltiplos nós simultaneamente (a própria definição de hiperaresta). Modelos avançados, como as Redes Convolucionais de Hipergrafo de Múltiplas Ordens, exploram operadores de convolução espectral de **2ª e 3ª ordem** para obter informações de vizinhança de ordem superior, estendendo a propagação de informações através de estruturas hierárquicas e vizinhanças mais amplas. (EN: **Higher-Order Hypergraph Convolution:** The term refers to the inherent ability of HNNs to capture complex interactions involving multiple nodes simultaneously (the very definition of a hyperedge). Advanced models, such as Multi-order Hypergraph Convolutional Networks, explore spectral convolution operators of **2nd and 3rd order** to obtain higher-order neighborhood information, extending information propagation through hierarchical structures and broader neighborhoods.)

## Statistics

- **Impacto na Pesquisa:** O artigo seminal de 2018 que introduziu o framework HGNN (arXiv:1809.09401) possui mais de **2200 citações**, indicando um alto impacto na comunidade de aprendizado de máquina.\n- **Otimização de Desempenho:** O framework **HyperGef** demonstrou um *speedup* de **2.25× a 3.99×** em modelos HyperGNN em comparação com implementações de última geração, destacando o foco em eficiência.\n- **Avanço Recente:** Modelos como o **HMHGNN** (Hyperbolic multi-channel hypergraph convolutional neural network) superam significativamente os modelos tradicionais de hipergrafo e redes neurais hiperbólicas em tarefas de classificação de nós, demonstrando o avanço contínuo na área. (EN: - **Research Impact:** The seminal 2018 paper that introduced the HGNN framework (arXiv:1809.09401) has over **2200 citations**, indicating a high impact on the machine learning community.\n- **Performance Optimization:** The **HyperGef** framework has demonstrated a *speedup* of **2.25× to 3.99×** on HyperGNN models compared to state-of-the-art implementations, highlighting the focus on efficiency.\n- **Recent Advancement:** Models like **HMHGNN** (Hyperbolic multi-channel hypergraph convolutional neural network) significantly outperform traditional hypergraph and hyperbolic neural network models in node classification tasks, demonstrating continuous advancement in the field.)

## Features

- **Modelagem de Ordem Superior:** Capacidade de codificar correlações de dados complexas e de ordem superior usando hiperarestas.\n- **Convolução de Hiperaresta:** Operador fundamental que generaliza a convolução de grafos para hipergrafos, permitindo a propagação eficiente de mensagens.\n- **Flexibilidade Multimodal:** Superior na manipulação de dados multimodais, onde diferentes tipos de dados ou relações podem ser representados por diferentes hiperarestas.\n- **Estrutura Geral:** Um framework geral que pode ser adaptado para várias tarefas de aprendizado de representação, como classificação de nós e reconhecimento visual.\n- **Implementações Otimizadas:** Suporte em bibliotecas de aprendizado profundo de grafos como PyTorch Geometric (PyG) e Deep Graph Library (DGL), com otimizações de desempenho como o framework HyperGef. (EN: - **Higher-Order Modeling:** Ability to encode complex, higher-order data correlations using hyperedges.\n- **Hyperedge Convolution:** Fundamental operator that generalizes graph convolution to hypergraphs, allowing for efficient message passing.\n- **Multimodal Flexibility:** Superior in handling multimodal data, where different data types or relationships can be represented by different hyperedges.\n- **General Framework:** A general framework that can be adapted for various representation learning tasks, such as node classification and visual recognition.\n- **Optimized Implementations:** Support in graph deep learning libraries like PyTorch Geometric (PyG) and Deep Graph Library (DGL), with performance optimizations such as the HyperGef framework.)

## Use Cases

- **Classificação de Redes de Citação e Reconhecimento Visual de Objetos:** Casos de uso originais que demonstraram a superioridade das HNNs sobre as GCNs.\n- **Detecção de Notícias Falsas (Fake News):** Utilização em modelos como o Hy-DeFake para analisar a propagação de notícias e as disparidades de atributos de usuários, modelando interações complexas de usuários e conteúdo.\n- **Saúde Inteligente:** Modelagem de dados multimodais em tempo real (sinais fisiológicos, comportamentais) coletados por dispositivos IoT e *wearables* para diagnóstico e monitoramento.\n- **Análise de Redes Sociais:** Modelagem de relações heterogêneas e de ordem superior (e.g., amizade, similaridade de itens, similaridade de usuários) para recomendação e análise de comportamento.\n- **Diagnóstico de Falhas:** Em equipamentos complexos, usando HNNs residuais para integrar abordagens baseadas em modelos e dados para detecção de anomalias.\n- **Processamento de Imagens:** Classificação de Imagens Hiperespectrais (HSI) e LiDAR, onde pixels são tratados como nós e superpixels como hiperarestas para capturar relações espaciais complexas.\n- **Bioinformática:** Fusão de informações multi-view (e.g., região cerebral-gene) para melhor interpretabilidade e análise de dados biológicos complexos. (EN: - **Citation Network Classification and Visual Object Recognition:** Original use cases that demonstrated the superiority of HNNs over GCNs.\n- **Fake News Detection:** Used in models like Hy-DeFake to analyze news propagation and user attribute disparities, modeling complex user-content interactions.\n- **Intelligent Healthcare:** Modeling real-time multimodal data (physiological, behavioral signals) collected by IoT and wearable devices for diagnosis and monitoring.\n- **Social Network Analysis:** Modeling heterogeneous and higher-order relationships (e.g., friendship, item similarity, user similarity) for recommendation and behavior analysis.\n- **Fault Diagnosis:** In complex equipment, using residual HNNs to integrate model-based and data-driven approaches for anomaly detection.\n- **Image Processing:** Classification of Hyperspectral Images (HSI) and LiDAR, where pixels are treated as nodes and superpixels as hyperedges to capture complex spatial relationships.\n- **Bioinformatics:** Fusion of multi-view information (e.g., brain region-gene) for better interpretability and analysis of complex biological data.)

## Integration

A integração de HNNs é tipicamente realizada usando bibliotecas de aprendizado profundo de grafos como **PyTorch Geometric (PyG)** ou **Deep Graph Library (DGL)**. O módulo `torch_geometric.nn.conv.HypergraphConv` em PyG implementa o operador convolucional de hipergrafo. O hipergrafo é representado por uma matriz de incidência esparsa, geralmente na forma de um tensor `hyperedge_index` de duas linhas (índices de nós e índices de hiperarestas).\n\n**Exemplo de Código (PyTorch Geometric):**\n\n```python\nimport torch\nfrom torch_geometric.nn import HypergraphConv\n\n# 1. Definir o Hipergrafo\n# Exemplo: V = {0, 1, 2, 3} e E = {{0, 1, 2}, {1, 2, 3}}\n# hyperedge_index: [ [índices de nós], [índices de hiperarestas] ]\nhyperedge_index = torch.tensor([\n    [0, 1, 2, 1, 2, 3], \n    [0, 0, 0, 1, 1, 1], \n])\n\n# 2. Definir as Features dos Nós\nnum_nodes = 4\nin_channels = 16\nout_channels = 32\nx = torch.randn(num_nodes, in_channels) # Features de entrada\n\n# 3. Instanciar e Aplicar a Camada de Convolução\nconv = HypergraphConv(in_channels, out_channels)\nx_out = conv(x, hyperedge_index)\n\n# x_out agora contém as features de saída (4 nós, 32 features)\nprint(f"Shape da Feature de Saída: {x_out.shape}")\n```\n\n**Fórmula de Convolução (Simplificada):**\n$$X' = D^{-1} H W B^{-1} H^T X \\Theta$$\n\nOnde $H$ é a matriz de incidência, $W$ é a matriz de pesos da hiperaresta, $D$ e $B$ são as matrizes de grau correspondentes, e $\\Theta$ é a matriz de parâmetros treináveis. (EN: HNN integration is typically done using graph deep learning libraries like **PyTorch Geometric (PyG)** or **Deep Graph Library (DGL)**. The `torch_geometric.nn.conv.HypergraphConv` module in PyG implements the hypergraph convolutional operator. The hypergraph is represented by a sparse incidence matrix, usually in the form of a two-row `hyperedge_index` tensor (node indices and hyperedge indices).)\n\n(EN: **Code Example (PyTorch Geometric):**\n\n```python\nimport torch\nfrom torch_geometric.nn import HypergraphConv\n\n# 1. Define the Hypergraph\n# Example: V = {0, 1, 2, 3} and E = {{0, 1, 2}, {1, 2, 3}}\n# hyperedge_index: [ [node indices], [hyperedge indices] ]\nhyperedge_index = torch.tensor([\n    [0, 1, 2, 1, 2, 3], \n    [0, 0, 0, 1, 1, 1], \n])\n\n# 2. Define Node Features\nnum_nodes = 4\nin_channels = 16\nout_channels = 32\nx = torch.randn(num_nodes, in_channels) # Input features\n\n# 3. Instantiate and Apply the Convolution Layer\nconv = HypergraphConv(in_channels, out_channels)\nx_out = conv(x, hyperedge_index)\n\n# x_out now contains the output features (4 nodes, 32 features)\nprint(f"Output Feature Shape: {x_out.shape}")\n```\n\n(EN: **Simplified Convolution Formula:**\n$$X' = D^{-1} H W B^{-1} H^T X \\Theta$$)\n\n(EN: Where $H$ is the incidence matrix, $W$ is the hyperedge weight matrix, $D$ and $B$ are the corresponding degree matrices, and $\\Theta$ is the trainable parameter matrix.)

## URL

https://arxiv.org/abs/1809.09401