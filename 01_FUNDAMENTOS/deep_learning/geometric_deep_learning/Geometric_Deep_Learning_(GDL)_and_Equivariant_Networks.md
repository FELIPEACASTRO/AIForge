# Geometric Deep Learning (GDL) and Equivariant Networks

## Description

Geometric Deep Learning (GDL) é um paradigma que visa generalizar modelos de Deep Learning para dados com estrutura geométrica subjacente, como grafos, malhas e variedades (manifolds), que são inerentemente não-Euclidianos. A proposta de valor única reside na incorporação de **vieses indutivos geométricos** (simetrias) diretamente na arquitetura da rede, utilizando a **Teoria de Grupos** como alicerce matemático. Isso resulta em **Redes Equivariantes**, onde a saída do modelo se transforma de maneira previsível (equivariância) ou permanece inalterada (invariância) sob transformações relevantes (e.g., rotações, translações). Essa abordagem melhora drasticamente a **eficiência de amostragem** e a **capacidade de generalização** dos modelos, sendo crucial para domínios como a química e a física. | Geometric Deep Learning (GDL) is a paradigm that aims to generalize Deep Learning models to data with underlying geometric structure, such as graphs, meshes, and manifolds, which are inherently non-Euclidean. The unique value proposition lies in incorporating **geometric inductive biases** (symmetries) directly into the network architecture, using **Group Theory** as the mathematical foundation. This results in **Equivariant Networks**, where the model's output transforms predictably (equivariance) or remains unchanged (invariance) under relevant transformations (e.g., rotations, translations). This approach drastically improves the **sample efficiency** and **generalization capability** of the models, being crucial for domains like chemistry and physics.

## Statistics

O benchmark **GeSS (Geometric Deep Learning under Scientific Applications with Distribution Shifts)** avalia modelos GDL (como EGNN e DGCNN) em cenários científicos (Física de Partículas, Ciência de Materiais, Bioquímica) sob mudanças de distribuição (Test-OOD). Resultados mostram que, em cenários de *Pileup Shift* ($\mathcal{Y}$-Conditional Shift), a **EGNN (Equivariant Graph Neural Network)** alcançou até **89.41% de Acurácia (ACC)** em dados de teste *out-of-distribution* (Test-OOD), enquanto o desempenho *in-distribution* era superior a 95%. Essa diferença ressalta o desafio da generalização OOD e a necessidade de arquiteturas robustas. | The **GeSS (Geometric Deep Learning under Scientific Applications with Distribution Shifts)** benchmark evaluates GDL models (such as EGNN and DGCNN) in scientific scenarios (Particle Physics, Materials Science, Biochemistry) under distribution shifts (Test-OOD). Results show that, in *Pileup Shift* ($\mathcal{Y}$-Conditional Shift) scenarios, the **EGNN (Equivariant Graph Neural Network)** achieved up to **89.41% Accuracy (ACC)** on *out-of-distribution* test data (Test-OOD), while *in-distribution* performance was above 95%. This gap highlights the challenge of OOD generalization and the need for robust architectures.

## Features

As principais características do GDL e das Redes Equivariantes incluem: **Generalização para Dados Não-Euclidianos** (grafos, nuvens de pontos, malhas); **Equivariância e Invariância** (o modelo respeita as simetrias inerentes aos dados, como a rotação de uma molécula); **Eficiência de Parâmetros** (a imposição de simetrias reduz o número de parâmetros livres, prevenindo *overfitting* e exigindo menos dados); e **Unificação de Arquiteturas** (o GDL fornece uma estrutura que engloba CNNs, GNNs e redes em variedades). | Key features of GDL and Equivariant Networks include: **Generalization to Non-Euclidean Data** (graphs, point clouds, meshes); **Equivariance and Invariance** (the model respects inherent data symmetries, such as the rotation of a molecule); **Parameter Efficiency** (imposing symmetries reduces the number of free parameters, preventing *overfitting* and requiring less data); and **Architecture Unification** (GDL provides a framework that encompasses CNNs, GNNs, and manifold networks).

## Use Cases

O GDL é fundamental em áreas onde a geometria e a simetria são cruciais: **Descoberta de Medicamentos (Drug Discovery)**, onde modelos com **equivariância a $E(3)$** (rotações, translações e reflexões) como o **NequIP** são usados para prever propriedades moleculares e interatômicas com alta eficiência de dados; **Física de Partículas (HEP)**, para reconstrução de trilhas de partículas em colisores como o LHC; **Ciência de Materiais**, para otimização de estruturas e previsão de propriedades de cristais; e **Visão Computacional 3D**, para processamento de nuvens de pontos e reconhecimento de objetos. | GDL is fundamental in areas where geometry and symmetry are crucial: **Drug Discovery**, where models with **$E(3)$ equivariance** (rotations, translations, and reflections) like **NequIP** are used to predict molecular and interatomic properties with high data efficiency; **Particle Physics (HEP)**, for particle track reconstruction in colliders like the LHC; **Materials Science**, for structure optimization and crystal property prediction; and **3D Computer Vision**, for point cloud processing and object recognition.

## Integration

A integração é realizada através de bibliotecas que estendem frameworks de Deep Learning existentes. As principais bibliotecas são: **`e2cnn`** (para $E(2)$ em PyTorch, focado em simetrias 2D) e **`e3nn`** (para $E(3)$ em PyTorch, focado em simetrias 3D, essencial para moléculas). Um exemplo de integração com `e2cnn` demonstra a definição do espaço de grupo (`gspaces.Rot2dOnR2`), dos tipos de campo (`nn.FieldType`) e a construção de camadas convolucionais equivariantes (`nn.R2Conv`) e de ativação (`nn.ReLU`), encapsulando o tensor de entrada em `nn.GeometricTensor`. | Integration is done through libraries that extend existing Deep Learning frameworks. The main libraries are: **`e2cnn`** (for $E(2)$ in PyTorch, focused on 2D symmetries) and **`e3nn`** (for $E(3)$ in PyTorch, focused on 3D symmetries, essential for molecules). An integration example with `e2cnn` demonstrates defining the group space (`gspaces.Rot2dOnR2`), field types (`nn.FieldType`), and constructing equivariant convolutional (`nn.R2Conv`) and activation (`nn.ReLU`) layers, by wrapping the input tensor in `nn.GeometricTensor`.

## URL

https://geometricdeeplearning.com/