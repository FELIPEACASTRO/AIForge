# Chain-of-Thought (CoT)

## Description
A técnica Chain-of-Thought (CoT), introduzida por Wei et al. (2022), é uma estratégia de engenharia de prompt que capacita Large Language Models (LLMs) a exibir capacidades de raciocínio complexo ao gerar uma série de etapas de raciocínio intermediárias antes de fornecer a resposta final. Essencialmente, ela imita o processo de pensamento humano de decompor um problema complexo em passos menores e gerenciáveis. Isso é particularmente eficaz para tarefas que exigem raciocínio lógico, aritmético ou de senso comum. A variante **Zero-Shot CoT** (Kojima et al., 2022) simplifica isso, exigindo apenas a adição da frase \"Vamos pensar passo a passo\" ao prompt, sem a necessidade de exemplos (few-shot). A **Auto-CoT** (Zhang et al., 2022) automatiza a geração dessas cadeias de raciocínio para demonstrações, otimizando o processo.

## Examples
```
1. **Zero-Shot CoT para Resolução de Problemas:**\n\n```\nPergunta: Fui ao mercado e comprei 10 maçãs. Dei 2 ao vizinho e 2 ao técnico. Depois, comprei mais 5 maçãs e comi 1. Com quantas maçãs eu fiquei?\n\nVamos pensar passo a passo.\n```\n\n2. **CoT Few-Shot para Raciocínio Aritmético:**\n\n```\nExemplo 1:\nQ: O número ímpar neste grupo soma um número par: 4, 8, 9, 15, 12, 2, 1.\nA: Os números ímpares são 9, 15, 1. A soma é 25. 25 é ímpar. Resposta: Falso.\n\nExemplo 2:\nQ: O número ímpar neste grupo soma um número par: 17, 9, 10, 12, 13, 4, 2.\nA: Os números ímpares são 17, 9, 13. A soma é 39. 39 é ímpar. Resposta: Falso.\n\nQ: O número ímpar neste grupo soma um número par: 16, 11, 14, 4, 8, 13, 24.\nA: \n```\n\n3. **CoT para Análise de Sentimento Complexa:**\n\n```\nAnalise o sentimento do seguinte comentário: \"O produto chegou no prazo, mas a embalagem estava danificada e o item não funcionou. O suporte, no entanto, foi rápido e resolveu o problema em 24h.\"\n\nInstrução: Gere uma cadeia de pensamento para justificar sua análise de sentimento (Positivo, Negativo, Neutro).\n```\n\n4. **CoT para Geração de Código com Explicação:**\n\n```\nTarefa: Escreva uma função em Python que calcule o fatorial de um número inteiro positivo.\n\nInstrução: Antes de fornecer o código, explique a lógica de implementação, incluindo a condição de parada e o loop de iteração.\n```\n\n5. **CoT para Raciocínio Lógico/Cenários:**\n\n```\nCenário: Um carro autônomo se aproxima de um cruzamento. A luz está verde, mas um pedestre entra na faixa de pedestres. O que o carro deve fazer?\n\nInstrução: Pense em voz alta sobre as prioridades (segurança, regras de trânsito) e as possíveis ações antes de dar a resposta final.\n```
```

## Best Practices
1. **Use Zero-Shot CoT como Ponto de Partida:** Sempre comece com a frase \"Vamos pensar passo a passo\" para tarefas de raciocínio. É a maneira mais simples e eficaz de ativar o CoT.\n2. **Estrutura e Formato:** Para CoT Few-Shot, garanta que os exemplos de raciocínio sejam claros, bem formatados e sigam um padrão consistente (Q: Pergunta, A: Raciocínio + Resposta).\n3. **Seja Explícito:** Em vez de apenas \"pense passo a passo\", use instruções mais detalhadas, como \"Gere uma cadeia de pensamento que inclua a decomposição do problema, a análise de cada parte e a conclusão final.\"\n4. **Combine com Outras Técnicas:** O CoT é frequentemente mais poderoso quando combinado com Few-Shot (CoT-Few-Shot) ou com técnicas mais avançadas como Tree-of-Thought (ToT) ou Self-Consistency.

## Use Cases
1. **Resolução de Problemas Matemáticos e Aritméticos:** Melhoria drástica na precisão de problemas de palavras (word problems) e cálculos complexos.\n2. **Raciocínio Lógico e de Senso Comum:** Tarefas que exigem inferência, como responder a perguntas de múltipla escolha complexas ou resolver quebra-cabeças.\n3. **Geração de Código e Depuração:** Explicar a lógica por trás de um trecho de código ou rastrear um erro, gerando o passo a passo da execução.\n4. **Análise de Documentos e Tomada de Decisão:** Decompor informações de um texto longo para justificar uma decisão ou resumir um argumento complexo.\n5. **Tradução e Interpretação:** Lidar com ambiguidades linguísticas, explicando as diferentes interpretações possíveis antes de escolher a tradução mais provável.

## Pitfalls
1. **Dependência do Tamanho do Modelo:** O CoT é uma capacidade emergente e só é eficaz em LLMs com um número suficiente de parâmetros (geralmente modelos maiores). Modelos menores podem não se beneficiar ou podem gerar cadeias de raciocínio incorretas.\n2. **Alucinações no Raciocínio:** O modelo pode gerar uma cadeia de pensamento que parece lógica, mas que contém erros factuais ou de cálculo, ainda chegando a uma resposta incorreta.\n3. **Aumento da Latência e Custo:** A geração da cadeia de pensamento aumenta o comprimento da resposta, o que consome mais tokens e, consequentemente, aumenta o tempo de resposta (latência) e o custo da API.\n4. **Ineficácia em Tarefas Simples:** Para tarefas simples de recuperação de fatos ou geração de texto criativo básico, o CoT pode ser desnecessário e apenas adicionar ruído ou custo.

## URL
[https://www.promptingguide.ai/techniques/cot](https://www.promptingguide.ai/techniques/cot)
