# BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding

**Área Vertical:** Deep Learning Avançado, NLP

**Categoria:** GitHub Repository

**Descrição:** Repositório oficial do Google Research contendo o código TensorFlow e modelos pré-treinados para o BERT, um modelo de linguagem baseado em Transformer.

**Relevância (1-10):** 10

**Palavras-Chave:** BERT, Transformer, NLP, Processamento de Linguagem Natural, Deep Learning, Transfer Learning, Google Research, TensorFlow

**URL:** https://github.com/google-research/bert

---

*Recurso extraído do processamento dos 9 arquivos não processados (397 URLs totais, 150 analisadas, 146 integradas)*
